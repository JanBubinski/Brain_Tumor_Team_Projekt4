{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7bbf15",
   "metadata": {},
   "source": [
    "# EfficientNet â€” czym jest i gÅ‚Ã³wna idea\n",
    "\n",
    "**EfficientNet** to rodzina efektywnych sieci konwolucyjnych (CNN) zaproponowana przez **Mingxing Tan i Quoc V. Le (Google, 2019)**.  \n",
    "ZostaÅ‚a stworzona, aby osiÄ…gaÄ‡ wysokÄ… dokÅ‚adnoÅ›Ä‡ w zadaniach wizji komputerowej przy **znacznie mniejszych kosztach obliczeniowych** niÅ¼ wczeÅ›niejsze modele (ResNet, DenseNet, Inception).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Czym jest?\n",
    "- Bazowy model **EfficientNet-B0** zostaÅ‚ znaleziony za pomocÄ… **Neural Architecture Search (NAS)**.  \n",
    "- Kolejne modele (**B1â€“B7**) powstajÄ… poprzez **skalowanie** bazowej architektury.  \n",
    "- W konstrukcji wykorzystano:\n",
    "  - bloki **MBConv** (*Mobile Inverted Bottleneck Convolution*),\n",
    "  - mechanizm uwagi **Squeeze-and-Excitation (SE)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ GÅ‚Ã³wna idea â€” *Compound Scaling*\n",
    "Zamiast powiÄ™kszaÄ‡ tylko jeden wymiar sieci (np. gÅ‚Ä™bokoÅ›Ä‡), EfficientNet skaluje **trzy jednoczeÅ›nie**:\n",
    "\n",
    "- **depth** â†’ gÅ‚Ä™bokoÅ›Ä‡ (liczba warstw),\n",
    "- **width** â†’ szerokoÅ›Ä‡ (liczba kanaÅ‚Ã³w w warstwach),\n",
    "- **resolution** â†’ rozdzielczoÅ›Ä‡ obrazu wejÅ›ciowego.\n",
    "\n",
    "Skalowanie odbywa siÄ™ wedÅ‚ug wzoru:\n",
    "\n",
    "depth       = Î±^Ï† <br>\n",
    "width       = Î²^Ï† <br>\n",
    "resolution  = Î³^Ï† <br>\n",
    "\n",
    "\n",
    "gdzie:\n",
    "- `Ï†` â€” wspÃ³Å‚czynnik skali (kontroluje wielkoÅ›Ä‡ modelu),  \n",
    "- `Î±, Î², Î³` â€” staÅ‚e dobrane empirycznie, aby uzyskaÄ‡ najlepszy balans.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Zalety\n",
    "- âœ… Bardzo wysoka dokÅ‚adnoÅ›Ä‡ przy maÅ‚ej liczbie parametrÃ³w.  \n",
    "- âœ… MoÅ¼liwoÅ›Ä‡ wyboru modelu B0â€“B7 w zaleÅ¼noÅ›ci od dostÄ™pnych zasobÃ³w.  \n",
    "- âœ… Dobre do transfer learningu w klasyfikacji obrazÃ³w i medycynie.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c91cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import random\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5f107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devic: cpu\n",
      "Dane juz istniejÄ…\n"
     ]
    }
   ],
   "source": [
    "def load(tr_path):\n",
    "    classes, class_paths = zip(*[(label, os.path.join(tr_path, label, image))\n",
    "                                 for label in os.listdir(tr_path) if os.path.isdir(os.path.join(tr_path, label))\n",
    "                                 for image in os.listdir(os.path.join(tr_path, label))])\n",
    "\n",
    "    return pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n",
    "\n",
    "SEED = 900729\n",
    "dir_path = './data'\n",
    "train_path = './data/Training'\n",
    "test_path = './data/Testing'\n",
    "validation_path = './data/Validation'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Devic: {device}\")\n",
    "\n",
    "if os.path.exists(dir_path):\n",
    "    print(\"Dane juz istniejÄ…\")\n",
    "else:\n",
    "    kaggle.api.authenticate()\n",
    "    kaggle.api.dataset_download_files('masoudnickparvar/brain-tumor-mri-dataset', path='./data', unzip=True)\n",
    "    tr_orginal_df = load(train_path)\n",
    "    ts_df = load(test_path)\n",
    "    val_df, tr_df = train_test_split(tr_orginal_df, train_size=0.25, random_state=SEED, stratify=tr_orginal_df['Class'])\n",
    "    validation_path = './data/Validation'\n",
    "    Path(validation_path).mkdir(exist_ok=True)\n",
    "\n",
    "    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    for class_name in classes:\n",
    "        class_validation_path = Path(validation_path) / class_name\n",
    "        class_validation_path.mkdir(exist_ok=True)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for idx, row in val_df.iterrows():\n",
    "        try:\n",
    "            source_path = Path(row['Class Path'])\n",
    "\n",
    "            filename = source_path.name\n",
    "            class_name = row['Class']\n",
    "            destination_path = Path(validation_path) / class_name / filename\n",
    "\n",
    "            shutil.move(str(source_path), str(destination_path))\n",
    "\n",
    "        except Exception as e:\n",
    "            errors.append({\n",
    "                'file': row['Class Path'],\n",
    "                'class': row['Class'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "\n",
    "    if errors:\n",
    "        print(f\"Errors: {len(errors)}\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error['class']}: {Path(error['file']).name} - {error['error']}\")\n",
    "\n",
    "    val_df_updated = val_df.copy()\n",
    "    val_df_updated['Class Path'] = val_df_updated.apply(\n",
    "        lambda row: str(Path(validation_path) / row['Class'] / Path(row['Class Path']).name),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    tr_df_updated = load(train_path)\n",
    "\n",
    "    val_df = val_df_updated\n",
    "    tr_df = tr_df_updated\n",
    "    print(\"PomyÅ›lnie pobrano dane\")\n",
    "\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=data_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=test_path, transform=data_transform)\n",
    "val_dataset   = datasets.ImageFolder(root=validation_path, transform=data_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf22d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fidok/Developer/WakacyjneWyzwanieSOLVRO-ML/FinalProject/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fidok/Developer/WakacyjneWyzwanieSOLVRO-ML/FinalProject/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = efficientnet_b0(pretrained=True)\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0913\n",
      "Zapisano nowy najlepszy model\n",
      "Epoch 2/10, Loss: 0.0618\n",
      "Zapisano nowy najlepszy model\n",
      "Epoch 3/10, Loss: 0.0521\n",
      "Zapisano nowy najlepszy model\n",
      "Epoch 4/10, Loss: 0.0400\n",
      "Zapisano nowy najlepszy model\n",
      "Epoch 5/10, Loss: 0.0422\n",
      "Epoch 6/10, Loss: 0.0381\n",
      "Zapisano nowy najlepszy model\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "if os.path.exists('best_model.pth'):\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    print(\"Wczytano zapisany model\")\n",
    "else:\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Zapisano nowy najlepszy model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "if val_loss < best_loss:\n",
    "    best_loss = val_loss\n",
    "    counter = 0\n",
    "    torch.save(model.state_dict(), 'best_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-tumor-team-projekt4 (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
