{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1e75dd",
   "metadata": {},
   "source": [
    "# Nazwa modelu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb86ea8",
   "metadata": {},
   "source": [
    "## Opis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c169355",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c7b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import random\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b188ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devic: cuda\n",
      "Dane juz istniejÄ…\n"
     ]
    }
   ],
   "source": [
    "def load(tr_path):\n",
    "    classes, class_paths = zip(*[(label, os.path.join(tr_path, label, image))\n",
    "                                 for label in os.listdir(tr_path) if os.path.isdir(os.path.join(tr_path, label))\n",
    "                                 for image in os.listdir(os.path.join(tr_path, label))])\n",
    "\n",
    "    return pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n",
    "\n",
    "SEED = 900729\n",
    "dir_path = './data'\n",
    "train_path = './data/Training'\n",
    "test_path = './data/Testing'\n",
    "validation_path = './data/Validation'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Devic: {device}\")\n",
    "\n",
    "if os.path.exists(dir_path):\n",
    "    print(\"Dane juz istniejÄ…\")\n",
    "else:\n",
    "    kaggle.api.authenticate()\n",
    "    kaggle.api.dataset_download_files('masoudnickparvar/brain-tumor-mri-dataset', path='./data', unzip=True)\n",
    "    tr_orginal_df = load(train_path)\n",
    "    ts_df = load(test_path)\n",
    "    val_df, tr_df = train_test_split(tr_orginal_df, train_size=0.25, random_state=SEED, stratify=tr_orginal_df['Class'])\n",
    "    validation_path = './data/Validation'\n",
    "    Path(validation_path).mkdir(exist_ok=True)\n",
    "\n",
    "    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    for class_name in classes:\n",
    "        class_validation_path = Path(validation_path) / class_name\n",
    "        class_validation_path.mkdir(exist_ok=True)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for idx, row in val_df.iterrows():\n",
    "        try:\n",
    "            source_path = Path(row['Class Path'])\n",
    "\n",
    "            filename = source_path.name\n",
    "            class_name = row['Class']\n",
    "            destination_path = Path(validation_path) / class_name / filename\n",
    "\n",
    "            shutil.move(str(source_path), str(destination_path))\n",
    "\n",
    "        except Exception as e:\n",
    "            errors.append({\n",
    "                'file': row['Class Path'],\n",
    "                'class': row['Class'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "\n",
    "    if errors:\n",
    "        print(f\"Errors: {len(errors)}\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error['class']}: {Path(error['file']).name} - {error['error']}\")\n",
    "\n",
    "    val_df_updated = val_df.copy()\n",
    "    val_df_updated['Class Path'] = val_df_updated.apply(\n",
    "        lambda row: str(Path(validation_path) / row['Class'] / Path(row['Class Path']).name),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    tr_df_updated = load(train_path)\n",
    "\n",
    "    val_df = val_df_updated\n",
    "    tr_df = tr_df_updated\n",
    "    print(\"PomyÅ›lnie pobrano dane\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac82900",
   "metadata": {},
   "source": [
    "# ðŸ§  ResNet â€“ Residual Network (Resztkowa SieÄ‡ Neuronowa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67363413",
   "metadata": {},
   "source": [
    "### Opis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a192f85",
   "metadata": {},
   "source": [
    "#### ðŸ”¹ Dlaczego powstaÅ‚?\n",
    "- Wraz ze wzrostem liczby warstw w sieciach neuronowych pojawiÅ‚ siÄ™ problem:\n",
    "  - **zanikajÄ…cy gradient** â€“ trudnoÅ›Ä‡ w trenowaniu bardzo gÅ‚Ä™bokich sieci,\n",
    "  - **degradacja dokÅ‚adnoÅ›ci** â€“ dodawanie kolejnych warstw pogarszaÅ‚o wyniki zamiast je poprawiaÄ‡.\n",
    "- Klasyczne sieci (np. VGG) nie byÅ‚y w stanie efektywnie uczyÄ‡ siÄ™ przy setkach warstw.\n",
    "\n",
    "#### ðŸ”¹ I wtedy powstaÅ‚ ResNet\n",
    "- ResNet wprowadza **poÅ‚Ä…czenia resztkowe (skip connections)**.\n",
    "- Zamiast uczyÄ‡ siÄ™ bezpoÅ›redniej funkcji `H(x)`, sieÄ‡ uczy siÄ™ **reszty** wzglÄ™dem wejÅ›cia:\n",
    "\n",
    "\\[\n",
    "H(x) = F(x) + x\n",
    "\\]\n",
    "\n",
    "gdzie:\n",
    "- `x` â€“ wejÅ›cie do bloku,\n",
    "- `F(x)` â€“ transformacja (np. sploty, normalizacja, ReLU),\n",
    "- `H(x)` â€“ wyjÅ›cie po dodaniu shortcutu.\n",
    "\n",
    "DziÄ™ki temu sieÄ‡ Å‚atwo uczy siÄ™ nawet **funkcji toÅ¼samoÅ›ciowej**, co stabilizuje trening.\n",
    "\n",
    "#### ðŸ”¹ Jak dziaÅ‚a blok resztkowy?\n",
    "Schemat dziaÅ‚ania jednego **Residual Block**:\n",
    "\n",
    "WejÅ›cie (x)<br>\n",
    "â†“<br>\n",
    "[Conv -> BN -> ReLU -> Conv -> BN] = F(x)<br>\n",
    "â†“<br>\n",
    "Dodanie shortcut: y = F(x) + x<br>\n",
    "â†“<br>\n",
    "ReLU<br>\n",
    "â†“<br>\n",
    "WyjÅ›cie (y)\n",
    "\n",
    "- **Shortcut (skip connection)** moÅ¼e byÄ‡:\n",
    "  - *Identity* â€“ gdy rozmiary siÄ™ zgadzajÄ…,\n",
    "  - *Conv 1x1* â€“ gdy trzeba dopasowaÄ‡ liczbÄ™ kanaÅ‚Ã³w lub rozdzielczoÅ›Ä‡.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22aeb32",
   "metadata": {},
   "source": [
    "### Architektura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed3e65e",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./screenshots/resnet_architecture.png\" alt=\"Resnet architecture\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df64c0",
   "metadata": {},
   "source": [
    "## Base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab5ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_path, transform=data_transform)\n",
    "test_dataset  = datasets.ImageFolder(root=test_path, transform=data_transform)\n",
    "val_dataset   = datasets.ImageFolder(root=validation_path, transform=data_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f921ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 4284\n",
      "    Root location: ./data/Training\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1428\n",
      "    Root location: ./data/Validation\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1311\n",
      "    Root location: ./data/Testing\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66c67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True) \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c59cab8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m imgs, labels = imgs.to(device), labels.to(device)\n\u001b[32m      8\u001b[39m optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     11\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torchvision/models/resnet.py:285\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torchvision/models/resnet.py:269\u001b[39m, in \u001b[36mResNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[32m    268\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv1(x)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(x)\n\u001b[32m    271\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/WakacyjneWyzwanieSOLVRO_ML/FinalnyProjekt/Brain_Tumor_Team_Projekt4/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:173\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_running_stats:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.momentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[32m    175\u001b[39m             exponential_average_factor = \u001b[32m1.0\u001b[39m / \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_batches_tracked)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-tumor-team-projekt4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
